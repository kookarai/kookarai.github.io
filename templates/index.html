<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>Record and Send Audio</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment@2.29.1/min/moment.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2.7.16"></script>
</head>

<body class="bg-gray-900 flex flex-col items-center justify-center min-h-screen p-4">
<div class="bg-gray-800 shadow-xl rounded-2xl p-8 w-full max-w-md" id="app">
    <div class="flex justify-between mb-6">
        <button :disabled="isRecording" @click="startRecording"
                class="bg-green-500 hover:bg-green-600 text-white py-3 px-4 rounded-lg transition ease-in-out transform hover:scale-105">
            Record
        </button>
        <button :disabled="!isRecording" @click="stopRecording"
                class="bg-red-500 hover:bg-red-600 text-white py-3 px-4 rounded-lg transition ease-in-out transform hover:scale-105">
            Stop
        </button>
    </div>

    <p class="text-gray-400 text-center mb-6">[[ status ]]</p>

    <!-- Playback for the original recorded audio -->
    <audio :src="originalAudioSrc" class="w-full mb-6 rounded-lg" controls v-if="originalAudioSrc"></audio>

    <!-- Playback for the AI-generated audio -->
    <audio :src="aiAudioSrc" class="w-full mb-6 rounded-lg" controls v-if="aiAudioSrc"></audio>

    <input class="w-full py-2 px-4 bg-gray-700 text-white rounded-lg mb-6" placeholder="Group Name" type="text"
           v-model="groupName">

    <input class="w-full py-2 px-4 bg-gray-700 text-white rounded-lg mb-6" id="datetime"
           placeholder="Choose date and time" type="text">

    <!-- Add Generate Audio Button -->
    <button :disabled="!audioBlob" @click="generateAudio"
            class="w-full bg-yellow-500 hover:bg-yellow-600 text-white py-3 px-4 rounded-lg mb-6">
        Generate AI Audio
    </button>
    
    <!-- Send Now Button -->
    <button :disabled="!aiAudioSrc" @click="sendNow"
            class="w-full bg-purple-500 hover:bg-purple-600 text-white py-3 px-4 rounded-lg mb-6">
        Send Now
    </button>
    
    <!-- Schedule Button -->
    <button :disabled="!canSchedule || !aiAudioSrc" @click="scheduleEvent"
            class="w-full bg-blue-500 hover:bg-blue-600 text-white py-3 px-4 rounded-lg">
        Schedule
    </button>
</div>

<script>
    let mainApp = new Vue({
      el: "#app",
      delimiters: ["[[", "]]"],
      data: {
        status: "Not recording...",
        isRecording: false,
        audioChunks: [],
        mediaRecorder: null,
        originalAudioSrc: null,  // Human audio (raw recorded audio) URL
        aiAudioSrc: null,        // AI-generated audio URL
        audioBlob: null,         // Store raw audioBlob before conversion
        datetime: "",
        groupName: "",
        modelID: "eleven_multilingual_sts_v2",
        voiceID: "DJDkcaY4POaxra3iaZ5b",
        apiKey: "sk_3b1e7773ad665bd2d039e2a2fdb987c214c1cf07ac63124b",
        supabaseUrl: "https://oqhygqxpxpdjtvaahwxk.supabase.co",
        supabaseKey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9xaHlncXhweHBkanR2YWFod3hrIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcyNTYxNTY5MSwiZXhwIjoyMDQxMTkxNjkxfQ.oYECwS4Y6ymOwGuXOVKh0lIWQVlgnbDOlDCfYY1AUVk",
        audioURL: null,
        scheduledEvents: [],
        voiceSettings: {
          stability: 0.5,
          similarity_boost: 0.75,
          style: 0.0,
          use_speaker_boost: true,
        },
      },
      computed: {
        canSchedule() {
          return this.audioURL && this.datetime && this.groupName;
        },
      },
      methods: {
        startRecording() {
            this.originalAudioSrc = null;
            this.aiAudioSrc = null;
            this.audioBlob = null;
            navigator.mediaDevices.getUserMedia({audio: true}).then(stream => {
                this.mediaRecorder = new MediaRecorder(stream);
                this.mediaRecorder.start();
                this.status = "Recording...";
                this.isRecording = true;
                this.mediaRecorder.ondataavailable = event => this.audioChunks.push(event.data);
            }).catch(() => alert("Mic access denied"));
        },
        stopRecording() {
            this.mediaRecorder.stop();
            this.mediaRecorder.onstop = () => {
                this.audioBlob = new Blob(this.audioChunks, {type: "audio/webm"});
                this.audioChunks = [];
                this.originalAudioSrc = URL.createObjectURL(this.audioBlob);  // Set the human audio for playback
                this.status = "Recording stopped. You can now listen to the original audio.";
            };
            this.isRecording = false;
        },
        generateAudio() {
            if (!this.audioBlob) {
                alert("No audio recorded yet.");
                return;
            }
    
            this.status = "Processing AI audio...";
    
            const form = new FormData();
            form.append("model_id", this.modelID);
            form.append("voice_settings", JSON.stringify(this.voiceSettings));
            form.append("audio", this.audioBlob);
    
            fetch(`https://api.elevenlabs.io/v1/speech-to-speech/${this.voiceID}`, {
                method: "POST",
                headers: {"xi-api-key": this.apiKey},
                body: form,
            }).then(response => response.blob()).then(blob => {
                this.uploadAudio(blob);
                this.aiAudioSrc = URL.createObjectURL(blob);  // Set the AI audio for playback
    
                // Remove the original human voice from the frontend
                this.originalAudioSrc = null;
                
                this.status = "AI Audio generated and ready for playback.";
            }).catch(() => this.status = "Error generating AI audio.");
        },
        uploadAudio(audioBlob) {
            const fileName = `audio-${Date.now()}.wav`;
            const formData = new FormData();
            formData.append("file", audioBlob, fileName);
    
            fetch(`${this.supabaseUrl}/storage/v1/object/audio/${fileName}`, {
                method: "POST",
                headers: {"Authorization": `Bearer ${this.supabaseKey}`, "apikey": this.supabaseKey},
                body: formData,
            }).then(response => {
                if (response.ok) this.audioURL = `${this.supabaseUrl}/storage/v1/object/public/audio/${fileName}`;
            }).catch(() => alert("Error uploading audio."));
        },
        sendNow() {
          if (!this.audioURL || !this.groupName) {
              alert("Audio not generated or group name missing.");
              return;
          }
  
          const payload = {
              url: this.audioURL,
              group: this.groupName,
              // scheduledAt is omitted for immediate sending
          };
          
          fetch("http://3.108.215.55/api/v1/forward-retool-audio", {
              method: "POST",
              headers: {
                  "Content-Type": "application/json",
              },
              body: JSON.stringify(payload),
          })
          .then(response => {
              if (!response.ok) {
                  return response.text().then(errorMessage => {
                      throw new Error(`HTTP error! status: ${response.status}, message: ${errorMessage}`);
                  });
              }
              return response.text(); 
          })
          .then(responseText => {
              this.status = "Message sent just now."; // Update status message
              this.aiAudioSrc = null; // Hide AI audio from frontend
          })
          .catch(error => {
              this.status = "Error sending audio now.";
          });
      },
  
      scheduleEvent() {
          if (!this.audioURL || !this.datetime || !this.groupName) {
              alert("Audio not generated, date/time, or group name missing.");
              return;
          }
  
          const payload = {
              url: this.audioURL,
              group: this.groupName,
              scheduledAt: moment(this.datetime).utc().format(), // Use UTC format for scheduling
          };
  
          fetch("http://3.108.215.55/api/v1/forward-retool-audio", {
              method: "POST",
              headers: {
                  "Content-Type": "application/json",
              },
              body: JSON.stringify(payload),
          })
          .then(response => {
              if (!response.ok) {
                  return response.text().then(errorMessage => {
                      throw new Error(`HTTP error! status: ${response.status}, message: ${errorMessage}`);
                  });
              }
              return response.text(); 
          })
          .then(responseText => {
              this.status = responseText; // Update status with server response
              this.aiAudioSrc = null; // Hide AI audio from frontend
          })
          .catch(error => {
              this.status = "Error scheduling event.";
          });
      },  
        getGroupNameFromURL() {
            const params = new URLSearchParams(window.location.search);
            const group = params.get("group");
            if (group) {
                this.groupName = group;
            }
        },
    },            
      mounted() {
        this.getGroupNameFromURL();
        this.$nextTick(() => {
            flatpickr("#datetime", {
                enableTime: true,
                dateFormat: "Y-m-d H:i",
                minDate: new Date(Date.now()), // Allow current time
                defaultDate: new Date(Date.now()), // Set default to current time
                onChange: (selectedDates, dateStr) => this.datetime = dateStr,
            });
        });
      },
    });
</script>
</body>
</html>
